---
layout: about
title: about
permalink: /
description: PhD student in Robotics at <a href="https://robotics.oregonstate.edu/">Oregon State University</a>.

profile:
  align: right
  image: prof_pic.jpg
  address: >
    <p>336 Rogers Hall</p>
    <p>2000 NW Monroe Ave</p>
    <p>Corvallis, OR 97331</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I am a Robotics PhD student at Oregon State University under the advising of [Dr. Kagan Tumer](http://web.engr.oregonstate.edu/~ktumer/). I received my B.Sc. in Computer Engineering from the University of North Carolina at Charlotte, *summa cum laude*.

Current research interests involve continuous control in dynamic environments with multiple objectives. I work at the intersection of evolutionary, deep, and reinforcement learning. How can an agent learn in situations where their goals are poorly-defined, or rewards are sparse? How can it learn to make trade-offs on the fly? What are the limits of a system's ability to adapt to changing environments and goals? I'm additionally interested in behavior space representations, neuroplasticity, and socially-conscious design.

(While you're here, did you [contribute to Wikipedia's fundraising](https://donate.wikimedia.org) this year?)
