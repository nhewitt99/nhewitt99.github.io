---
layout: about
title: about
permalink: /
description: MS student in Robotics at <a href="https://robotics.oregonstate.edu/">Oregon State University</a>. he/him.

profile:
  align: right
  image: prof_pic.jpg
  address: >
    <p>201 Graf Hall</p>
    <p>1680 SW Monroe Ave</p>
    <p>Corvallis, OR 97331</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I am a Robotics MS student at Oregon State University under the advising of [Dr. Kagan Tumer](http://web.engr.oregonstate.edu/~ktumer/). I received my B.Sc. in Computer Engineering from the University of North Carolina at Charlotte, *summa cum laude*.

Current research interests involve continuous control in dynamic environments with multiple objectives. I work at the intersection of evolutionary, deep, and reinforcement learning. How can an agent learn in situations where their goals are poorly-defined, or rewards are sparse? How can one learn to make trade-offs on the fly? What are the limits of a system's ability to adapt to changing environments and goals? I'm additionally interested in behavior space representations, neuroplasticity, and socially-conscious design.

I enjoy backpacking, rock climbing, and reading [weird books](https://www.goodreads.com/review/list/141415479-nathan?ref=nav_mybooks&shelf=read). While I have your attention, have you [contributed to Wikipedia's fundraising](https://donate.wikimedia.org) this year?
